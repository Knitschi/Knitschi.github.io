<?xml version="1.0" encoding="UTF-8"?>
<add>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFBuildscripts</field>
    <field name="url">df/de6/_c_p_f_buildscripts.html</field>
    <field name="keywords"></field>
    <field name="text">The CPFBuildscripts package provides python scripts for simplifying the CMake calls of CPF projects The scripts can be used for configuring and building a CPFCMake project CMake projects usually require calls to CMake to generate makefiles and build the project Depending on the project the calls can require quite a list of arguments The python scripts provided by the CPFBuildscripts package use the knowledge about the structure of the CPF project to reduce the length of those commands It is therefore highly recommended to use the CPFBuildscripts package in combination with the CPFCMake package Index</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFCMakeAPIDocs</field>
    <field name="url">d9/dfc/_c_p_f_c_make_a_p_i_docs.html</field>
    <field name="keywords"></field>
    <field name="text">API Documentation This page holds the documentation of the CMake functions that are provided to the users of the CPFCMake package CPFCMake introduces some variables of global scope that may be of interest to the clients CPF_MINIMUM_CMAKE_VERSION The minimum cmake version required by the CPF This can be used by clients in their own calls to cmake_minimum_required() CPF_CI_PROJECT This is set to name of the CI parent project and allows to use the name after calling cpfInitPackageProject() which overrides the CMAKE_PROJECT_NAME variable with the name of the package project This must be included at the top of your root CMakeLists.txt file It adds all CPF modules to the CMAKE_MODULE_PATH allows including them with their short filenames only It sets the global variable CPF_MINIMUM_CMAKE_VERSION and checks that the currently run CMake version meets the requirement Sets the CMake policies that are required for CPF projects It includes further CPF modules that are needed in the root CMakeLists.txt file This module provides the following function cpfAddPackages() The function is called in all CPF CI-projects This calls add_subdirectory() for all the packages that are defined in the package.cmake file This adds the global custom targets GlobalTargets Initiates some global variables GLOBAL_FILES This option can be used to add further files to the globalFiles target This module provides the following function cpfInitPackageProject() This macro is called at the beginning of a cpf-packages CMakeLists.txt file This function calls the project() function to create the package-level project It automatically reads the version number of the package from the packages git repository or a provided version file and uses it to initiated the cmake variables PROJECT_VERSION and PROJECT_VERSION_&lt;digit&gt; variables CI project vs package projects This module provides the following function cpfAddCppPackage() Adds a C++ package to a CPF project The name of the package is the same as the name of the directory in which the packages CMakeLists.txt file is located The function provides a large list of options that allow defining the features that the package should provide A C++ package consists of a main binary target that has the same name as the package and some helper binary targets for tests and test utilities Providing the function with optional arguments will switch on more of CPF s functionality like test-targets code-analysis packaging or documentation generation Custom targets PACKAGE_NAMESPACE The parameter is used in the following ways CPFCMake assumes this is the C++ namespace that you use in the package The name is used as a namespace in the packages generated C++ version header file As a namespace for the packages cmake target names The value is used as a part of the packages generated export macro which must be prepended to all exported classes and functions in a library If you use the GENERATE_PACKAGE_DOX_FILES option the default package documentation page will generate a documentation of that namespace TYPE The type of the main binary target of the package GUI_APP Executable with switched of console Use this for Qt applications with GUI CONSOLE_APP Console application LIB Library INTERFACE_LIB Header only library BRIEF_DESCRIPTION A short description in one sentence about what the package does This is included in the generated documentation page of the package and in some distribution package types LONG_DESCRIPTION A longer description of the package This is included in the generated documentation page of the package and in some distribution package types HOMEPAGE A web address from where the source-code and/or the documentation of the package can be obtained This is required for Debian packages MAINTAINER_EMAIL An email address under which the maintainers of the package can be reached This is required for Debian packages PUBLIC_HEADER All header files that declare functions or classes that are supposed to be used by consumers of a library package The public headers will automatically be put into binary distribution packages while header files in the PRODUCTION_FILES are not included PRODUCTION_FILES All files that belong to the production target If the target is an executable there should be a main.cpp that is used for the executable PUBLIC_FIXTURE_HEADER All header files in the fixture library that are required by external clients of the library If the fixture library is only used by this package this can be empty FIXTURE_FILES All files that belong to the test fixtures target TEST_FILES All files that belong to the test executable target LINKED_LIBRARIES The names of the library targets that are linked to the main binary target LINKED_TEST_LIBRARIES The names of the library targets that are linked to the test fixture library and the test executable Use this to specify dependencies of the test targets that are not needed in the production code like fixture libraries from other packages PLUGIN_DEPENDENCIES This keyword opens a sub-list of arguments that are used to define plugin dependencies of the package Multiple PLUGIN_DEPENDENCIES sub-lists can be given to allow having multiple plugin subdirectories The plugin targets are shared libraries that are explicitly loaded by the packages executables and on which the package has no link dependency If a target in the list does not exist when the function is called it will be silently ignored If a given target is an internal target an artificial dependency between the plugin target and the packages executables is created to make sure the plugin is compilation is up-to-date before the executable is build Adding this options makes sure that the plugin library is build before the executable and copied besides it in the PLUGIN_DIRECTORY Sub-Options PLUGIN_DIRECTORY A directory relative to the packages executables in which the plugin libraries must be deployed so they are found by the executable This if often a plugins directory PLUGIN_TARGETS The name of the targets that provide the plugin libraries DISTRIBUTION_PACKAGES This keyword opens a sub-list of arguments that are used to specify a list of packages that have the same content but different formats The argument can be given multiple times in order to define a variety of package formats and content types The argument takes two lists as sub-arguments A distribution package is created for each combination of the elements in the sub-argument lists For example argument DISTRIBUTION_PACKAGES DISTRIBUTION_PACKAGE_CONTENT_TYPE CT_RUNTIME_PORTABLE DISTRIBUTION_PACKAGE_FORMATS ZIP 7Z will cause the creation of a zip and a 7z archive that both contain the packages executables and all depended on shared libraries Adding another argument DISTRIBUTION_PACKAGES DISTRIBUTION_PACKAGE_CONTENT_TYPE CT_RUNTIME DISTRIBUTION_PACKAGE_FORMATS DEB will cause the additional creation of a debian package that relies on external dependencies being provided by other packages Sub-Options DISTRIBUTION_PACKAGE_CONTENT_TYPE CT_RUNTIME The distribution-package contains the executables and shared libraries that are produced by this package This can be used for packages that either do not depend on any shared libraries or only on shared libraries that are provided externally by the system CT_RUNTIME_PORTABLE listExcludedTargets The distribution-package will include the packages executables and shared libraries and all depended on shared libraries This is useful for creating packages that do not rely on any system provided shared libraries The CT_RUNTIME_PORTABLE keyword can be followed by a list of depended on targets that belong to shared libraries that should not be included in the package because they are provided by the system CT_DEVELOPER The distribution-package will include all package binaries header files and cmake config files for importing the package in another project This content type is supposed to be used for binary library packages that are used in other projects Note that for msvc debug configurations the package will also include source files to allow debugging into the package The package does not include dependencies which are supposed to be imported separately by consuming projects CT_SOURCES The distribution-package contains the files that are needed to compile the package DISTRIBUTION_PACKAGE_FORMATS 7Z TGZ TXZ TZ ZIP Packs the distributed files into one of the following archive formats 7z tar.bz2 tar.gz tar.xz tar.Z zip DEB Creates a debian package deb file This will only be created when the dpkg tool is available DISTRIBUTION_PACKAGE_FORMAT_OPTIONS A list of keyword arguments that contain further options for the creation of the distribution packages SYSTEM_PACKAGES_DEB This is only relevant when using the DEB package format The option must be a string that contains the names and versions of the debian packages that provide the excluded shared libraries from the CT_RUNTIME option E.g on which the package depends VERSION_COMPATIBILITY_SCHEME This option determines which versions of the package are can compatible to each other This is only of interest for shared library packages For compatible versions it should be possible to replace an older version with a newer one by simply replacing the library file or on linux by changing the symlink that points to the used library Not that it is still the developers responsibility to implement the library in a compatible way This option will only influence which symlinks are created output file names and the version.cmake files that are used to import the library Currently only ExactVersion scheme is available so you do not need to set this option Schemes ExactVersion This option means that different versions of the library are not compatible This is the most simple scheme and relieves developers from the burdon of keeping things compatible ENABLE_ABI_API_COMPATIBILITY_CHECK_TARGETS bool This option can be used to override the global CPF_ENABLE_ABI_API_COMPATIBILITY_CHECK_TARGETS setting GENERATE_PACKAGE_DOX_FILES If this option is given the package will generate a standard package documentation dox file The file contains the brief and long package description as well as some links to other generated html content like test-coverage reports or abi-compatibility reports Example Here is an example of an CMakeLists.txt file for a library package This module provides the following function cpfAddCppPackage() This function creates a target that does nothing but is only used as a file container This makes sure that the files are included in a Visual Studio solution SOURCES A list of files that are added to the package The paths must be relative to the current source directory or absolute This module provides the following function cpfAddDoxygenPackage() This function adds a package that runs the doxygen documentation generator on the owned packages of your CI-project The package can also contain extra files containing global documentation that does not belong to any other package All files specified with the key-word arguments are added to the targets source files More information about the documentation generation can be found on the page Documentation generation and in the tutorial PROJECT_NAME The value of this argument is the name that appears in the header of the doxygen documentation This is set to the name of the CI-project if no value is specified Note that this overrides the value of the PROJECT_NAME variable in the DOXYGEN_CONFIG_FILE DOXYGEN_CONFIG_FILE This must be set to the absolute path of the Doxygen configuration file You should be aware that the file is not directly passed to Doxygen In order to inject the values of CMake variables into the Doxygen configuration the file is used as a template to generate the file Generated/ config txt This generated file is the one that is used as the input for the call of Doxygen After building the new package for the first time you can open the file and see that it overwrites some values of the configuration variables at the bottom of the file The following variables in the configuration file are overwritten Changing them in the given template will have no effect DOXYGEN_LAYOUT_FILE Absolute path to the used DoxygenLayout.xml file DOXYGEN_STYLESHEET_FILE Absolute path to the used DoxygenStylesheet.css file SOURCES Additional files that will be parsed by doxygen and that can contain global documentation ADDITIONAL_PACKAGES Packages that are not owned by this ci-project but should also be parsed by doxygen in order to add them to the documentation HTML_HEADER The header.html file used by doxygen HTML_FOOTER The footer.html file used by doxygen PROJECT_LOGO An svg or png file that is copied to the doxygen output directory and can then be used in the documentation PLANT_UML_JAR The absolute path to the plantuml.jar which doxygen uses to generate UML-diagramms from PlantUML code in doxygen comments Setting this enables you to use Doxygen s startuml command RUN_DOXYINDEXER This option can be added to also run the doxyindexer tool to generate the searchdata.db directory that is required when using the server-side search feature of doxygen The directory will be created in the Generated/ config directory</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFConfiguration</field>
    <field name="url">d7/d8d/_c_p_f_configuration.html</field>
    <field name="keywords"></field>
    <field name="text">CPF configurations Add documentation of the default configurations example configs etc Maybe put the section about the configuration mechanism from the working with a cpf project in here</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake</field>
    <field name="url">da/daa/_c_p_f_c_make.html</field>
    <field name="keywords"></field>
    <field name="text">The CPFCMake package implements a standardized C++ CMake project with additional CI functionality This package is the most basic component of the CMakeProjectFramework It helps with setting up a CMake based C++ project with extended functionality The package tries to solve the following problems Abstraction of common CMake code to a higher level CMakeProjectFramework projects are set up by using only a handfull of CMake functions This removes implementation details from the CMakeLists.txt files Providing a standardized directory structure for a C++ project Providing additional CI tasks like code-analysis or documentation-generation as custom targets Package-versioning based on version tags provided by the Git repository Modularisation of the code base into individual CMake packages Use of cmake configuration files which contain build configurations that outlive the deletion of the build directory and the CMakeCache.txt file Index API Documentation CPF configurations Custom targets Test targets Distribution packages Documentation generation Versioning</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFCustomTargets</field>
    <field name="url">df/d03/_c_p_f_custom_targets.html</field>
    <field name="keywords"></field>
    <field name="text">Custom targets The build pipeline of a CPF project is implemented with CMake custom-targets In order to execute one of those tasks separately from the whole pipeline one has to build that target with the 3_Make py script The advantage of the custom-target mechanism is that the used build-system handles dependency issues rebuilding outdated targets and parallelizing task execution The availability of custom-targets in a CPF project depends on the projects configuration and its source files Most custom targets can be disabled via the configuration file This may be helpful if a custom implementation of the task is preferred Some tasks require a test executable which is only created if the package has a source file that defines the main function of a test-executable In some IDEs like Visual Studio or KDevelop targets are visualized and can be directly build from within the IDE This may sometimes be preferred to building the targets from the command line The following sections contain lists with the names of available custom targets The lists do not contain some private targets of the CPF that are only created as sub-steps of the targets that are of interest to the user A CPF project contains some targets that operate on the global level They either execute operations that can not be done for each package in separation or bundle up a certain kind of per-package targets In this case building the bundle target will simply build all per-package targets of that kind Here is a list of targets that can exist once per CPF project abi-compliance-checker acyclic ALL_BUILD clang-tidy distributionPackages globalFiles install opencppcoverage pipeline runAllTests runFastTests valgrind ZERO_CHECK Here is a list of targets that can exist once per CPF package abi-compliance-checker_ package clang-tidy_ package distributionPackages_ package opencppcoverage_ package package package _fixtures package _tests runAllTests_ package runFastTests_ package valgrind_ package This target bundles the abi-compliance-checker_ package targets The target checks that the projects target dependency graph is acyclic This target can be disabled with the CPF_ENABLE_ACYCLIC_TARGET variable This target builds all binary targets This target bundles the clang-tidy_ package targets This target bundles the distributionPackages_ package targets This is only a file container target that does not execute any commands It holds all source files that are of global scope like tool configuration files global documentation etc This CMake standard target copies all installed files to the directory specified with CMAKE_INSTALL_PREFIX Not that this includes runtime files developer files external shared library dependencies and source files This target bundles the opencppcoverage_ package targets It also combines the temporary output of the opencppcoverage_ package targets into the final html report that can be found in the html output directory The top-level bundle target that will make sure that all other targets are built This target bundles the runAllTests_ package targets This target bundles the runFastTests_ package targets This target is not contained in the pipeline target which always builds the runAllTests target This target bundles the valgrind_ package targets A CMake default target that runs the CMake generate step This is a bundle target that runs the Abi-Compliance-Checker tool The target only exists for project configurations that use Gcc with debug flags and for shared library packages Report compatibility The basic functionality is to create html reports that compare the abi/api-compatibility of a previous libray package version with the current one The reporst are added to the project web-page To enable this the target must be able to download previously generated distribution packages of that package from the project web-page which must contain generated abi-dump files This complex requirement makes the target somewhat fragile This functionality can be disabled with the CPF_ENABLE_ABI_API_COMPATIBILITY_CHECK_TARGETS config variable Enforce compatibility You can also enable targets that will fail to build if abi or api compatibility is hurt by your current changes This option can be switched on in stable branches To do so use the CPF_CHECK_ABI_STABLE and CPF_CHECK_API_STABLE config variables This target only exists when compiling on Linux with the clang compiler It runs the clang-tidy tool on the packages source files The target can be disabled with the CPF_ENABLE_CLANG_TIDY_TARGET config variable Creates all distribution packages of the package A distribution package is a file that is distributed to users of the package This can be a zip file that contains the binaries or sources or an installer The target is only created if the addPackage() function has the DISTRIBUTION_PACKAGES argument set This target runs the test executable with OpenCppCoverage tool in order to create an html report that shows the code lines that are hit while running the tests This target will only exist for project configurations that use MSVC and will only run the tool when compiling in Debug configuration The target can be disabled with the CPF_ENABLE_OPENCPPCOVERAGE_TARGET config variable The main binary target of the package An additional library that can be used to share test utility code between packages It is only created if the addPackage() function has the FIXTURE_FILES and PUBLIC_FIXTURE_HEADER arguments set The test executable that belongs to the package This target is only created if the addPackage() function has the TEST_FILES argument set The executable should run automated tests when executed This target runs all the tests in the package _tests executable The target can be disabled with the CPF_ENABLE_RUN_TESTS_TARGET config variable This target runs all the tests in the package _tests executable that have either the word FastFixture or FastTests included in their name It is the the users responsibility to make sure that the tests with those names are really fast tests The purpose of the target is to provide a way of executing only tests that are run quickly an which are therefor useful when working in a tight test-driven development cycle The target can be disabled with the CPF_ENABLE_RUN_TESTS_TARGET config variable This target runs the test executable with the Valgrind tool which can help to detect memory leaks or undifined behavior The target only exists for project configurations that use Gcc or Clang with debug flags When this target is enabled you must also add the empty file Other/MyPackageValgrindSuppressions.supp file to all packages You can use this file to suppress false positives or unfixable issues that are found by Valgrind The target can be disabled with the CPF_ENABLE_VALGRIND_TARGET config variable</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFDistributionPackages</field>
    <field name="url">d3/d64/_c_p_f_distribution_packages.html</field>
    <field name="keywords"></field>
    <field name="text">Distribution packages Discuss package creation and package consumption</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFDocumentationGeneration</field>
    <field name="url">dc/d68/_c_p_f_documentation_generation.html</field>
    <field name="keywords"></field>
    <field name="text">Documentation generation Currently the CPF provides the cpfAddDoxygenPackage() function to integrate Doxygen based documentation generation into the CI-pipeline Adding a doxygen package adds a custom target that runs doxygen with all the owned packages as input The search functionality is configured to use the server-side search approach as described here To make it work these points must be implemented The DoxygenConfig.txt must contain the correct value for the SEARCHENGINE_URL key This means that the url of the doxysearch.cgi file must be known and accessible before generating the documentation When the url of the documentation web-server changes this value must be changed too One can test if the cgi script works by entering This should return test succesfull The file search/search.js in the doxygen directory should also contain a correct linkt to the doxysearch.cgi file The web-server needs access to the right doxysearch.cgi file which is provided by Doxygen The doxysearch.cgi file must come from the same version of doxygen that is used to generate the html files and the doxysearch.db search database The webserver must be configured to use cgi scripts which is done by providing the serve-cgi-bin.conf file with the docker-image of the webserver The Dockerfile makes sure the file is copied into the container The help generation needs to execute the doxyindexer.exe to create the doxysearch.db serach-index for the doxysearch.cgi This is done in the python script 7_GenerateDocumentation.py The generated files must be copied to the documentation server container with the command CMake allows to generate a dependency graph for the packages in a CI-project This dependency graph can be integrated into your doxygen documentation The doxygen target will also create a second transitive reduced version of the dependency graph The transitive reduced graph does not show direct dependencies when an indirect dependency exists This resulst in a cleaner graph which may sometimes be favoured to the complete graph These graphs can be added to the documentation by adding the lines to one of your doxygen comments</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFCMakeTestTargets</field>
    <field name="url">d1/d4f/_c_p_f_c_make_test_targets.html</field>
    <field name="keywords"></field>
    <field name="text">Test targets Explain about test targets and the command line interface What options will the cpf give to the test exe in order to run fast tests and hand over test file directories Should it be possible for users to hand over their own options</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFCMake::CPFVersioning</field>
    <field name="url">d3/dae/_c_p_f_versioning.html</field>
    <field name="keywords"></field>
    <field name="text">Versioning This page contains information on how the versioning problem is handled in the CPF The source of a version number is the Git repository that contains the package or CI-repository During the generate step The CPF determines the current version number of each package by reading the release version tags of the repository This version number is then used by the CPF while creating distribution packages or in the production code Because of the fully automated versioning-pipeline of a CPF project developers can rely that builds of two different commits will never have the same version number All repositories that are used for a CPF project should have the release version tag 0.0.0 at one of their first commits The CPF requires at least one release version tag for its versioning mechanism to work Package ownership Format major minor patch Examples 1.0.1 0.0.99 The version tags must follow the given pattern in order to be recognized by the CPF Tags of this form are called release versions The CPF assumes that the commits with the release versions are the ones that are provided to clients Release version tags must be manually added to the repository when the developer deems a commit worthy to be published This can also be done via the build-job that is provided by the CPFMachines package Format major minor patch commit-nr hash Examples 1.0.1.13 0.0.99.1 In order to have different version numbers for each build the CPF will determine internal version numbers for each package whenever the generate step is executed The first three digits are derived from the latest release version number that can be seen from the current commit in one of its preceding commits The commit-nr is the number of commit that have been made since the commit that has the release version This allows to see if an internal version is older or younger than another internal version However the commit number alone does not make the version unique as the development could have branched since the last release version This could lead to two commits with the same version number For this reason the version number also contains the first digits of the commit hash This part will be as long as is needed to make it unique If the repository has local changes that have not yet been committed the optional postfix is added to the version number Dirty versions can in general not be rebuild by other developers and should therefore not be considered when trying to reproduce bugs For C++ packages the CPF will automatically generate a header file that contains the current version number The version can be obtained in the C++ code by using assuming that you have a package MyPackage with namespace mp The package version can be accessed in the CMakeLists.txt file of the package via the PROJECT_VERSION variable after the call of the cpfInitPackageProject() function if you want to generate your own version files In the CPF the version tags in the repository are also used to mark commits for which the pipeline target was successfully build This is only enforced in combination with the build-job that is provided by the CPFMachines package The build-job adds version tags after successfully building a commit When this policy is followed developers can quickly see which commits are worth checking out when they try to build older versions Version numbers are incremented by adding new release version tags to the repository This can either be done manually or by setting certain parameters to the build-job that is provided by the CPFMachines package The CPF assumes that release version tags are unique and ordered where smaller versions can only be followed by larger versions Before you manually add a release version tag you should also make sure that the pipeline target of that commit builds for all your supported configurations The build-job of the CPFMachines package will make sure that all of these requirements are met when incrementing version numbers Tagging a commit with a release version</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesHookSetup</field>
    <field name="url">d7/d1f/_c_p_f_machines_hook_setup.html</field>
    <field name="keywords"></field>
    <field name="text">Automatic build-Job execution In day to day development it is practical when the build-job is run automatically whenever a developer pushes commits that should be integrated into a main branch of the project To enable that CPFJenkinsjob provides a python module that adds hook scripts to the repositories of your CPF-projects Add documentation for hook config and how to run it</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesConfigFile</field>
    <field name="url">dd/d47/_c_p_f_machines_config_file.html</field>
    <field name="keywords"></field>
    <field name="text">The CPFMachines config file This page should provide information about all the parameter in the config file and what they do</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines</field>
    <field name="url">d4/d62/_c_p_f_machines.html</field>
    <field name="keywords"></field>
    <field name="text">The CPF infrastructure includes a Jenkins server build slaves and web-servers for hosting the generated html pages This package provides a python script for setting up these servers The setup script requires a user provided configuration file and ssh access to all involved machines in the network The jenkins server can be configured to contain build-jobs for CPF based repositories For each of these projects a web-server is set up to host the html content that is generated by the CPF-projects build pipeline CPFMachines also provides a python script to deploy post-receive hooks to the cpf-project repositories From all the packages in the CMakeProjectFramework CPFMachines is the least seasoned one Users still have to do a lot of manual work like setting up ssh servers and manual installation of build-tools on the windows build-slaves Index How to setup the CPFMachines infrastructure Automatic build-Job execution The CPFMachines config file The jenkins build-job Machines and Container Manual Tests Current problems</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFJenkinsJob</field>
    <field name="url">d7/dd1/_c_p_f_jenkins_job.html</field>
    <field name="keywords"></field>
    <field name="text">The jenkins build-job The jenkins job that is created by this package is a parameterized job The parameters can be used to execute multiple tasks on a CPF CI-project when the job is started via the Jenkins web-interface In this mode the job verifies the commits made to an integration branch by building the pipeline in all configurations merge the commits to a main branch and add a new internal-version tag to mark the commit as a successful build The project web-page will be updated with the latest version of the generated documentation This mode is the most common use case which should be triggered automatically when pushing commits to an integration branch of the build repository or one of the package repositories To do an integration job following parameters must be set branchOrTag origin/ name MainBranch task integration package If a package was changed this must be set to the package name Note that this must be a package that has its versioning handled by this build project all other can be left at their defaults In this mode the job will overwrite an existing internal version tag with a release version and rebuild the tagged commit to create build artifacts with the new version In this case you need to specify which part/digit of the version number should be incremented The less significant digits are reset to zero This will also update the projects web-page To create a release tag the following parameters must be set branchOrTag existing internal version-tag task one of incrementMajor incrementMinor incrementPatch all other can be left at their defaults Sometimes it is necessary to rebuild an already integrated commit in order to recreate build artifacts In this mode the job will not touch the version tags are changed This will also update the projects web-page When none of the jobs default parameters are changed it executes this task for the master branch To rebuild an existing commit the following parameters must be set branchOrTag version-tag all other can be left at their defaults When working on the CMakeProjectFramework itself it is sometimes useful to speed up the build-job by running it with a reduced workload and without modifying the repository Reducing the workload can be achieved by limiting the build to a special configuration and/or a special target In this case the following parameters must be set branchOrTag origin/ someBranch this should be the branch you work on task rebuild package The package you work on cpfConfiguration The configuration you are interested in target The target that is build After a successful build the jenkins job accumulates the html output from all configurations that are specified in the cpfCIBuildConfigurations.json file This is done because not all pipeline steps are available for all configurations For example the OpenCppCoverage report can only be generated on Windows and would miss if only the html-pages generated by a Linux configuration were published The Doxygen output can be created by all configurations and only one will be used in the accumulated html output The build-job will take the output from the last configuration in cpfCIBuildConfigurations.json file that generates it This may be important when you want to use the output of a special configuration Note that the configuration can influence the actual content of the documentation an example is the dependency graph in which the node shapes are different for shared and static libraries After accumulation the content of the html directory is copied to the web-server that belongs build project and can be accessed via that server In case you want to use a custom jenkins-job for publishing the webpage the CPF-job creates a build-artifact that contains the complete html directory</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesContainer</field>
    <field name="url">d2/d67/_c_p_f_machines_container.html</field>
    <field name="keywords"></field>
    <field name="text">Machines and Container This section contains information about the machines and containers that are used to host the services that are needed to run the CPF build-pipeline Machine Setup This section describes which machines virtual machines and docker images are used to provide the development infrastructure for the CppCodeBase project Currently the setup includes the native Debian machine Feldrechengeraet This native machine runs three docker containers and a virtual Windows 10 machine The pipeline requires a windows based build-slave for Jenkins which is currently implemented as a virtual machine This machine has been configured manually and then a backup was made The backup is stored on the DatenBunker machine in the directory The medium-term goal is to remove the need for stored virtual machines and replace them with containers or virtual machines plus scripts that will do the machine setup This is supposed to improve the of the state of the build-machines because all the scripts that define them are contained in the repository Setting up the involved docker containers on Linux only requires the execution of the setupDockerContainer.sh script that can be found in the Infrastructure/DockerImages directory of the CppCodeBase Starting The Linux Docker Containers Currently the following machines are implemented as Linux based docker containers Documentation-Server Hosts the html pages that are generated by the build pipeline Currently this is the Doxygen documentation and a report from the OpenCppCoverage tool Jenkins-Master The machine that runs the Jenkins master and which is accessed to observer the build-pipeline Jenkins-Slave-Linux-0 The machine on which the actual builds of the Linux parts of the pipeline are done To set these machines up one needs a debian machine that has docker and git installed Then the CppCodeBase repository needs to be checked out in order to get the scripts One also needs to create a directory that will act as the home directory of the jenkins-master and is shared between the host and the container Currently this directory is hardcoded to which may need to be transformed to an script argument later The Infrastructure/DockerImages folder ccbContains the setupDockerContainer.sh script which does all the work Running it will require an working ssh connection to Datenbunker machine in order to setup the connection from the jenkins-master to the Datenbunker Network issues after running setupDockerContainer.sh Setting up the docker container changes the network settings of the host This may cause the the setupDockerContainer.sh script to fail when run multiple times in a row because connection to the internet can not be made Restarting the machine on which the script is run will solve the problem The Windows Slave There is a virtual machine that is used as a build-slave for the parts of the pipeline that must be build on Windows The machine runs the OpenSSH server that is shipped with Windows All the tools that are needed for running the CPF pipeline jobs are installed manually The Jenkins Build Server The server is setup in the jenkins-master container Manual changes to the server via the web-interface are lost when the setupDockerContainer.sh is re-run This includes updates to plugins and jenkins itself Therefore non-experimental changes must be implemented by changing the files in the Infrastructure/DockerImages directory The web-page of the jenkins-server is here There is a post-commit hook that starts the pipeline The pipeline script builds the pipeline target on Linux and Windows in two configurations each The pipeline script collects html output of the pipeline and copies it to a web-server Git The Git repository is hosted on the DatenBunker machine in the directory The repository has a post-commit-hook that triggers the CppCodeBase_Build_Pipeline job on the Jenkins server Buy a more powerfull build-machine to reduce the overall pipeline time</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesTests</field>
    <field name="url">de/d5a/_c_p_f_machines_tests.html</field>
    <field name="keywords"></field>
    <field name="text">Manual Tests This is a list of non automated tests This should only be a stopgap solution until they are automated Tests for versioning mechanics Running a successful build for an already pushed commit without a version tag should add an internl version tag to that commit Setting a release version tag should only work when the build is run on an internal version tag It should not be possible to create a release version tag that already exists When createin a release version the old internal version tag should be deleted Owned packages should be updated during the job run if new commits are available The job should fail when release tagging a non owned package</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesProblems</field>
    <field name="url">d9/daf/_c_p_f_machines_problems.html</field>
    <field name="keywords"></field>
    <field name="text">Current problems Current Problems Machine names in the config.json files should be given in lower case only or problems with authenticating ssh server hosts can occur I was not able to make name resolution for windows machines in the host network work inside the docker containers The machine names for the windows build-slaves therefore must be given as ip addresses to allow the jenkins-master to reach them All machines should be within a trusted network as machine to machine communication is currently vulnerable to man in the middle attacks due to ignoring ssh host key checking When the machines access git repositories with the https protocol the passwords for these repositories are stored in plain text via the git credential store mechanism on the build slaves and the jenkins master machine Trouble Shooting The scripts in the CPFMachines package rely on a rather complex environment that must be setup manually A lot can go wrong here so here is a list of the most common problems Add list Notes With the current implementation parallel execution of the build-job is not possible This is because the version of a commit must stay the same while the job is running because the current version number is retrieved multiple times from the repository while the job is running Chaning the number in the meantime would lead to inconsistencies In the longer run it would be good to remove this limitation which could be a showstopper for highly frequented projects with long buildtimes Another problem is that we do not get a build for each push which makes it harder to pinpoint failed builds to a specific push/developer When using the CPF on Windows one may be hitting the 260 character limit for filenames On Windows 10 this limit can be switched off When building on older windows versions the user can try to reduce the length of his configuration names package names or ci-project name</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFMachines::CPFMachinesUsage</field>
    <field name="url">de/d15/_c_p_f_machines_usage.html</field>
    <field name="keywords"></field>
    <field name="text">How to setup the CPFMachines infrastructure Requirements At least one Linux Machine For Windows builds an additional Windows machine is required All machines must be in a local network that also contains the machine that runs the setup script All machines must be accessible via OpenSSH from the script-runner Linux machines use the sshd service provided that can be installed with apt-get The Windows machines use the OpenSSH server that is shipped with Windows Linux machines must have docker installed Windows machines must have the slave.jar copied to On windows slaves all build-tools that are required to run the CPF pipeline must be manually installed Setup infrastructure on fresh systems and complete the list This section has overlapping content with Setting up the CPF CI server infrastructure We should merge them together Setting up the infrastructure After setting up the host-machines and getting the CPFMachines package you are ready to set up the servers that are involved in the CPF infrastructure If you want to use the infrastructure for multiple projects it is recommended that you create an extra CPF-project that holds the configuration files that are needed when running the setup scripts If you use the jenkins server for a single CPF-project you can add the configuration files to the global files if that project In both cases you will have to add the CPFMachines and most likely the CPFJenkinsjob package to the CPF-project that holds the configuration files Machine configuration Automatically add the content of the example config file here and manually add comments Running the script When you added the configuration file to the project you are ready to go Start the setup script by running in the root directory of your project This may take some time because some of the tools required for the pipeline build need to be compiled while setting up the docker container If everything went well the script ends with the output If you used the example config file you should now be able to access the Jenkins web-interface under http://MyMaster:8080 and the projects web-server under http://MyMaster:80 However the links to your projects will only work after running their build-jobs Change webserver file structure that multiple project pages can be served serachindex and an index.html in the base directory provides links to the single projects</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFTests</field>
    <field name="url">d5/d25/_c_p_f_tests.html</field>
    <field name="keywords"></field>
    <field name="text">A package that contains automated tests of the CMakeProjectFramework This package is not intended to be used by clients but rather implements mid- and high-level tests of the CPF As the tests in this package may test multiple packages at once and require some test setup-code to be run they where put in their own package Index</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFBasicConcepts</field>
    <field name="url">df/d2a/_c_p_f_basic_concepts.html</field>
    <field name="keywords"></field>
    <field name="text">Basic Concepts This pages describes the general ideas behind the CMakeProjectFramework It introduces some terms that are used throughout the documentation of this project The CPF follows the following key concepts Provide a Multi repository approach approach that allows the distribution of the code base over multiple repositories Define the build infrastructure completely in text-files that can be held in a repository This allows to quickly set up the infrastructure from a small amount of data The repository also provides the change history for the system Hide all CMake features behind a smaller declarative interface While cmake offers the functionality to solve all problems that occur when setting up a C++ code-base it is still quite some work to implement a solution The CPF wants to take that burden from its users while trying not to loose too much of the generality that a custom implementation would offer Keep files of three different live expectancies in three different directories Sources Configurations and generated files Keeping the generated files out of the source-tree has become the norm when using CMake This allows deleting the build-tree in order to guarantee a fresh system However in the standard CMake workflow the generated files also contain the manually defined project configuration within the CMakeCache.txt file For complex projects defining a configuration may take some time and deleting it together with the generated files is undesirable The CPF therefore puts the configuration information in a directory that is parallel to the build-* and It also allows defining multiple configurations at the same time Let the build system handle parallelism and up-to-date checks The CPF takes advantage of CMake s custom target mechanism This way the advanced tasks like test-runs code-analysis or documentation generation may be run in parallel and are only re-run when they are outdated Separate the CI-code from the production code by putting it into the CI-project repository Read more in CI project vs package projects In a CPF project the code that implements the CI-job is separated from the payload code The payload code can be split up into multiple packages To achieve this a CPF project has two CMake project levels The CI project is created in the root CMakeLists.txt file It provides the interface for the CI-job and the developers to build a set of packages and defines which configurations are build by the CI-system The project repository can also contain some higher level documentation that does not really belong to a single package but rather the group of packages that is owned by the CI project In the Sources subdirectory we have the package directories that contain the CMakeLists.txt files that define the package projects Each package creates one main binary that is supposed to be used by consumers This can be a library or an executable The package can also contain other arbitrary files like test-code image resources documentation and everything else that belongs to that piece of functionality For small code bases it is practical to keep all files in a single repository This avoids version conflicts and keeps the project nice and simple This means however that a change in a a lower lever library must always be pulled through* for all components that use the library A change in one cpp file will always trigger the build-job for the whole world One can imagine that this does not scale for a growing code-base The CPF therefore supports splitting up the code-base into multiple repositories and multiple build-jobs A CPF project can be started with the simple single repository and single build-job approach and later be split up in multiple repositories and multiple build-jobs One should be aware though that this introduces a noticeable increase in complexity The git work will increase and and version conflicts become possible Each CI-project repository defines a CI-build-job for multiple packages and each package can have its own repository which is recommended for packages that are consumed by multiple CI-projects Add a nice diagram of a monolithic project vs a distributed one A package can be owned by a CI project or be an external package If a package is owned by a CI project it means that this CI project is responsible for running the automated tests of the package and defining the officially supported build configurations of that the package When using the CPFMachines CI-job it will also be the entity that marks successful builds of owned packages with version tags An owned package can either be included in the CI projects git repository or it can be a git submodule with its own repository If it uses a git submodule it is called a loose owned package In this case it s version number can advance independently of the CI-repository Packages that are intended to be used in other projects should be loose packages with their own repository to allow other projects to include the package as a git submodule Loose packages lead to more and more complex git work meaning that more git operations will be necessary in the day to day work If packages are executables or not used in other projects it is therefore recommended to make them fixed packages and check them directly into the CI repository External packages are always git submodules The CI project s build-pipeline will not run the tests for these packages and exclude them when generating the documentation An external project should have another CI project that owns that package</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFIntroduction</field>
    <field name="url">d4/d68/_c_p_f_introduction.html</field>
    <field name="keywords"></field>
    <field name="text">Introduction When setting up a C++ Software project multiple tasks besides writing the actual C++ code arise Organizing the code-base into smaller packages Versioning of the packages Automatic acquisition of external software dependencies Creating distribution packages that can be consumed by others Setting up a build pipeline that also does additional tasks like running automated test static/dynamic analysis generate documentation etc Setting up a CI-server to run the pipeline Setting up a homepage for the project that hosts the documentation The CMakeProjectFramework tries to solve the above mentioned problems by using a combination of common open source tools from the C++ ecosystem The third party tools used by the CMakeProjectFramework are Git code versioning CMake meta-buildsystem Cotire CMake module for pre-compiled headers Jenkins CI server Doxygen documentation generator clang-tidy static code analysis valgrind dynamic code analysis OpenCppCoverage measure test coverage Abi Compliance Checker visualize changes in the API/ABI between package versions Graphviz used to create a dependency graph of the project Using the CPF should relieve you of writing your own higher level CMake code or other additional scripts to implement pipeline tasks It can additionally provide a Jenkins CI infrastructure that is in the future completely generated from text-files</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFProjectOrganisation</field>
    <field name="url">da/dca/_c_p_f_project_organisation.html</field>
    <field name="keywords"></field>
    <field name="text">Project Organization The CMakeProjectFramework master repository contains some of the documentation of the CMakeProjectFramework and provides the configuration for its official build job The master repository also serves as an for the packages that implement the various aspects of the CI system The packages are located in their own repositories and added as Git submodules to the master repository The packages are CPFCMake Contains CMake code that implements the additional CI tasks as custom targets CPFBuildscripts Provides python scripts that shorten the frequently used CMake calls CPFMachines Provides a python script that sets up a Jenkins-CI server and web-servers that provide CI-jobs for CPF-projects Package Dependencies Here is a simplified graph the illustrates the dependencies between the packages of the CMakeProjectFramework MyBuildRepository represents a project that uses the CMakeProjectFramework In the long run the dependency between CPFCMake and CPFMachines should be removed by making CPFCMake acquire all of the third party software via hunter instead of using the pre-installed software from the build slaves Dependencies The CppCodeBase cmake setup uses the hunter package manager to download and compile some of its dependencies During the configuration process you can define the HUNTER_ROOT directory that will be used by hunter to build and store some of the external dependencies If you you alread use hunter in another project make sure to set the variable to the same directory that is used by the other project in order to save compilation time and disk space for dependencies that are used by multiple projects</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFSettingUpACPFProject</field>
    <field name="url">d9/dc9/_c_p_f_setting_up_a_c_p_f_project.html</field>
    <field name="keywords"></field>
    <field name="text">Setting up a CPF project This section shows how to create a CPF based project Before doing so it is recommended that you get acquainted with the CMakeProjectFramework by building the example project as described on the Working with a CPF project page Basic knowledge of CMake and how to work with Git is probably helpful but it should be possible to step through this tutorial without any preexisting knowledge of those tools This tutorial will walk you through the steps that are required to create a CPF project It starts with a very simple project that will then be extended to show more advanced features The goal of the tutorial is not only to create a new CPF project but also to explain some of it s details in the process If you already know your way around a CPF project and you just want to create a new one it is probably quicker if you simply copy the example project and remove the stuff that you do not need and rename the rest This tutorial assumes that you work on Windows with Visual Studio 2017 It also assumes that you can run CMake and the python scripts from the command line without prepending the extra python command If you want to run this tutorial on Linux you have to use the base Linux configuration in the configuration step instead of the Windows configuration You may also want to choose different names for your generated configurations like VS Gcc and VS2017-shared Gcc-shared Until not stated differently all commands should be executed in the projects root directory When running things on Linux there are a few differences The build output directory for the example executables is a slightly different directory with an additional bin subdirectory When running executables you have to prepend to the executable file At some places you may have to replace with You will have to replace commands for filesystem operations with their Linux equivalents First you need a Git repository that will hold your CI project For simplicity s sake we create the remote git repository on the same machine that we use for working on the cloned repository If you are familiar with setting up remote Git repositories you can also create it on a different machine Navigate to a directory that is suited for holding the repositories If you are on Windows make sure that it is a short path Because of the deep nested directory structure your CPF project may get into trouble with the 260 character path limit Create the directory MyCPFProject.git This will contain the remote repository Now open a command line and create the remote repository by executing the following commands Clone the remote repository by executing the following commands This will create the MyCPFProject directory This is the root directory of your project that we will use to add and edit source files In the next section we will add some basic files to that repository We now have the repository that will hold the files of our project First we add the basic files that are required for a CPF project You now have to create the files with the following content gitignore The file will make sure that directories and files that are generated by the CPF are ignored by git CMakeLists.txt This is the root CMakeLists.txt file of your CPF project include Including cpfInit cmake provides us with the CPF_MINIMUM_CMAKE_VERSION that is used in the next line Alternatively you can set your own minimum version that must be equal or higher then the version that is required by the CPF The cpfInit cmake file also includes further files to make the cpfAddPackages() function available that is used later cpfInit cmake also adds the cmake modules of the CPF to the CMAKE_MODULE_PATH which allows you to use the short include syntax from here on project(MyCPFProject) This creates the so called CI project cpfAddPackages() This function adds the packages to the CI project The function reads the value of the CPF_PACKAGES variable in the packages.cmake file and adds them to the project by calling add_subdirectory() cpfAddPackages() also initiates some global variables and targets of the CPF packages.cmake This file defines which packages are added with the call of cpfAddPackages() For now we have no packages available so the value of the package list CPF_PACKAGES stays empty We will modify this file later when we add our first packages Add the basic files to the repository After creating the files you should now commit them to the repository and add a first version tag The tag is required by the CPF to determine the version number of the packages If it is missing the CPF will later cause errors In the last section you added a CMakeLists.txt file that uses some functions from the CPFCMake package However you do not have those functions yet available in your project To change that we now add two packages as git submodules Open a command line and navigate to the Sources directory Then run The submodules CPFCMake and CPFBuildscripts are part of the CMakeProjectFramework Adding them to the source tree is not enough We also have to add them to the packages.cmake file as EXTERNAL packages Now that we have acquired the CPF packages we can run the generate step to see if everything works Run the following commands in the project root directory This will creates the Configuration and Generated directories parallel to your Sources directory Your file tree should now look like this Our CI project is now ready The only thing that is missing is some actual C++ code In order to add some payload code we add our first package to the MyCPFProject repository This is a package that creates an executable Add the following file tree to the Sources directory Set the content of the new files in the MyApp directory as follows CMakeLists.txt include(cpfInitPackageProject) Provides the cpfInitPackageProject() function include(cpfAddCppPackage) Provides the cpfAddCppPackage() function cpfInitPackageProject() This creates the package project and sets the PROJECT_VERSION variables set briefDescription and set longDescription Basic descriptions of what your package does The values may be used in auto-generated documentation or in distribution packages set PACKAGE_PRODUCTION_FILES A list with the currently available source files of the package This is a CMakeLists.txt file after all set PACKAGE_LINKED_LIBRARIES A list with targets on which the created package depends For now we have no dependencies so the list is empty cpfAddCppPackage() This function adds all the binary and custom targets that belong to a CPF C++ package The bigger part of CPFCMake s functionality lies beneath this function function.cpp This is a simple C++ file that implements a function It represents your C++ code The file includes the generated file cpfPackageVersion_MyApp.h header which provides function ma::getPackageVersion() that returns the current version number Note that the include directories and the project directory structure in the CPF is laid-out that all includes can uniformly be written with include package/file.h As recommended in the section for the CMakeLists.txt file we put our package functions into namespace ma function.h Note the use of the MA_EXPORT export macro The macro is provided by the ma_export.h header which is generated by CMake Export macros are normally only needed when building shared libraries However it is good practice to let the clients of a library decide whether they want to use it as a shared or static a library So better make sure that you always add the export macro to symbols that are intended to be used by clients If you do not add the macro in a shared library you will get linker errors We get the MA prefix because we added the PACKAGE_NAMESPACE ma to the call of cpfAddCppPackage() main.cpp The CPF expects the main function to be in the file main.cpp In the case of a package that creates an executable the CPF internally creates a static library that contains all sources except the main.cpp file This is done to allow linking the complete functionality to a test executable that may also be created We now have to tell the CI-project that we added an owned package We do this by adding MyApp to the packages.cmake file Finally commit the new files to the repository by running With all the files in place we can now generate and build the project Note that you have to run a fresh generate whenever you change the packages.cmake file A fresh generate is executed when the configuration option is given to the 2_Generate.py script After that you can build the pipeline target and run the application Your actual version number will be different and depends on the current state of your repository You can read more about the CPF versioning here At this point our pipeline does not contain a lot of additional functionality The only thing to note here is that cpfAddCppPackage() created a library libMyApp and the executable MyApp-debug For our first build we used one of the default configurations that are shipped with the CPF Linux or Windows In this section we add our own default configuration to the project Default configurations can be though of as configurations that are officially supported by our project They are typically the configurations that are build by the continuous integration server You can find more detailed information about configurations in the CPF here For demonstration purposes we change the configuration to build shared libraries instead of static libraries To create the new default configuration execute the following steps First we create a new configuration file that sets a different value for variable BUILD_SHARED_LIBS This variable is used to tell CMake to build shared libraries instead of static ones This will change our implementation library libMyApp into a shared library Instead of using the command line options you can also edit the configuration file with a text-editor which may be more convenient if multiple values are changed Then we move the new configuration to the projects default configurations directory Sources/CIBuildConfigurations With the second configure step we use the new default configuration as our new local VS configuration We regenerate our make-files with the new configuration At the end we commit the new configuration file to the repository Developers can now inherit from the new default configuration VS2017-shared instead of manually setting all the required CMake variables in the 1_Configure.py step As your C++ project grows it will at some point be reasonable to split it into multiple libraries With the CPF we create libraries by adding a library package In this example we assume that our library will be used by other projects To Allow this we create a separate repository for the library package We then add this repository as a git submodule to our MyCPFProject repository If you do not know if a library will be shared between projects you can first add it directly to the CI repository to avoid the extra overhead of working with a git submodule If need be you can still put it in it s own repository later Create a new repository with the name MyLib using the same steps that you executed when creating the MyCPFProject repository You should end up with two empty repositories MyLib.git and MyLib Both lie besides the MyCPFProject.git and MyCPFProject directories We will first add some files to the MyLib repository and then add it as git submodule to MyCPFPRoject Add the following text-files to the MyLib repository and set the content as listed in the sections below CMakeLists.txt This file has some differences compared to the MyApp\CMakeLists.txt file We changed the name of the namespace and the description of the package We changed the TYPE argument in the cpfAddCppPackage() call in order to create a library package We added the PUBLIC_HEADER argument to the cpfAddCppPackage() call Libraries must provide public headers for consumers With the argument we can say which of our headers are supposed to be public Each library needs at least one public header or the project will fail to build function.cpp function.h Add the new files to the MyLib repository Now add commit and push all files in the MyLib repository We also add an initial version tag for the MyLib repository Now add MyLib as a loose owned package to MyCPFProject as a git submodule by running in the MyCPFProject/Sources directory This will yield a MyCPFProject/Sources/MyLib directory that contains the files that you created in the above section To finish the process of adding the MyLib package we have to extend some files in MyCPFProject packages.cmake We add the MyLib package as owned package to CI project by adding it in the packages.cmake file As the variable description states it is essential that MyLib is added to the list before MyApp or cmake will not be able to find MyLib when it adds MyApp MyApp/CMakeLists.txt To make the functionality of MyLib available in MyApp we have to add it to the linked libraries of MyApp MyApp/function.cpp We extend our original ma::function() to also call the ml::function() from MyLib You now have to commit the changes to MyCPFProject and regenerate the make-files in order to finish adding the library package You can see that MyApp successfully calls the new function from MyLib Again your version numbers will be different MyLib has a different version then MyApp because it lives in a different repository The CPF packages are designed to create an extra executable that runs automated tests for the packages production code This section will show you how to enable such a test executable for the MyLib package Add the new file MyLib_tests_main.cpp to a new Tests directory with the content In a real project you would probably use the main function that is provided by your test-framework instead of writing your own Note that we placed the file into the arbitrary Tests subdirectory which allows us to keep some order in our package Change the packages CMakeLists.txt file content to this We added two new lists PACKAGE_TEST_FILES and PACKAGE_LINKED_TEST_LIBRARIES and handed them to the cpfAddCppPackage() function The PACKAGE_TEST_FILES list should contain all source files that are used to build the test executable the PACKAGE_LINKED_TEST_LIBRARIES list can be used to add linked libraries that are only used by the test executable This could be a test-framework library for example In this example our test executable does not depend on any other library so we leave this empty You can now build and run your test executable by calling Somewhere in the build-log you should see the text output of the executable Note that tests will not be re-run if you execute the build command a second time You have to edit at least one source file of the package in order to outdate the test-run If you then rebuild the runAllTests target it will automatically create new binaries and run the tests with those For more information about the test targets of a CPF package see Test targets When writing a lot of automated tests it may become necessary to re-use test utility code from one package in another This could be fake or mock classes that you provide to replace the real objects in tests To make that possible the CPF can create an extra fixture library per package that can contain reusable test code To demonstrate this add two files function_fixture.h and function_fixture.cpp to the MyLib package with the following content and add them to the CMakeLists.txt file as shown below Sources/MyLib/Tests/function_fixture.h Note that the fixture library uses a different export macro then the production library Sources/MyLib/Tests/function_fixture.cpp Sources/MyLib/CMakeLists.txt For the fixture library we have to distinguish between public header files and other source files Add the new files to new list variables and as arguments to the cpfAddCppPackage() call as shown below Sources/MyLib/Tests/MyLib_tests_main.cpp Use the new function in the test code The fixture library is called package _fixtures and is automatically linked to the test executable If you need it in the tests of another package you have to add it to that packages PACKAGE_LINKED_TEST_LIBRARIES variable You can now compile and run your tests by calling One part of a CI pipeline is to create some sort of package that can be downloaded by the users of the software For applications this is usually an installer which can be arbitrarily complex For libraries however this often is just a ZIP archive that either holds the complete source code or the compiled artifacts and public headers In the CPF nomenclature we call these package files distribution packages in order to distinguish them from the CPF code packages in the Sources directory The CPF has enough information about your package to create the simple compressed archive packages for you To enable creating distribution packages you have to add one more argument to the cpfAddCppPackage() function Sources/MyLib/CMakeLists.txt Note that the DISTRIBUTION_PACKAGES argument requires a list of nested key-word arguments due to the complexity of the option The options in this example will cause the creation of a developer binary package in the 7z and zip format Developer binary* means that the package will contain the compiled binaries and public headers We also set options for creating a tar.gz archive that contains the package sources For more information about creating other kinds of distribution packages read Distribution packages In order to create the specified packages run You should now have a directory MyCPFProject/Generated/VS/html/Downloads/MyLib/LastBuild with the three archives MyLib version Windows.src.tar.gz MyLib version Windows.dev.Debug.7z MyLib version Windows.dev.Debug.zip The packages are added to the html directory so they can be directly downloaded from the projects web-page This is an optional feature and you can skip this step if you do not want to use cotire Cotire is a third party cmake module that implements the automatic use of pre-compiled headers You can use this in your CPF project to speed up your builds First you need to add cotire as an external package by executing Note that we actually added a fork of cotire that was changed to better integrate with the CPF We now add cotire to our external packages in the packages.cmake file As a last step we enable the use of cotire in our configuration Note that at this point we will not get much benefit from using cotire Cotire will only add headers from external dependencies to the pre-compiled header and we only use iostream Note that cotire will also add a compiler option to include the generated prefix header which is not available to clients of our libraries Therefore you should make sure that your headers include everything they need To enforce that you can have a configuration that uses CPF_ENABLE_PRECOMPILED_HEADER OFF This configuration will fail to build if you forget to include any headers that are also included with the prefix header This is an optional feature and you can skip this step if you do not want to use Doxygen as a documentation generator In order to use this feature you have to download and install Doxygen on your developer machine and add it to the PATH so you can run it from the command line The CPF provides you with the cpfAddDoxygenPackage() function that can be used to add a custom target that runs Doxygen on your CI-project Doxygen parses your source files for special comments and generates an html documentation from it We now add our own package that holds files for our global documentation This package contains the doxygen configuration files and files that contain global documentation that does not really belong to any of your packages Now add the following files It is not required to use documentation as the name of the package The name of the package directory is also the name of the target that is later build to generate the documentation CMakeLists.txt In this CMakeLists.txt file we add a custom-target package instead of the C++ packages that we added in the previous steps MyProject.dox This is an example of a file that contains global documentation We use doxygen to create the default versions of the config files DoxygenConfig.txt DoxygenLayout.xml DoxygenStylesheet.css header.html and footer.html You can change these files to customize the content and looks of the generated html pages For further information refer to the Doxygen documentation Finally we add the package to the repository and the packages.cmake file packages.cmake To harvest the fruits of your hard labor run You can now open Generated/VS/html/doxygen/html/index.html in your browser to take a look at the generated html-page There is not much to see here because we have not added much content yet The CPF can generate a standard doxygen documentation for your C++ packages that contains the descriptions from the CMakeLists.txt files To activate this feature we add the GENERATE_PACKAGE_DOX_FILES options to the cpfAddCppPackage() calls in Sources/MyLib/CMakeLists.txt and Sources/MyApp/CMakeLists.txt You can now re-build your documentation target and the html-page should contain Modules sub-pages for the MyLib and MyApp packages that contain the description strings and some links to other generated content For more details see Documentation generation You now know the basics about setting up a CPF project If you still have open questions feel free to add an issue on github with your question</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFSettingUpTheInfrastructure</field>
    <field name="url">d9/d9a/_c_p_f_setting_up_the_infrastructure.html</field>
    <field name="keywords"></field>
    <field name="text">Setting up the CPF CI server infrastructure This page contains a tutorial on how to use the scripts provided by the CPFMachines package to set up a continuous integration server infrastructure for you CPF projects The tutorial assumes that you are familiar with the Working with a CPF project and the Setting up a CPF project tutorials The tutorial also assumes that you have a CPF project provided by a remote git repository that can be pulled and pushed to via the SSH protocol It assumes you can clone that repository with The main functionality of the CPFMachines package is provided by a python script setup.py The script accesses the machines that belong to your environment over SSH in order to setup a Jenkins CI server build slaves and web-servers for your CPF project pages The script reads a configuration json file that contains values like machine access data the number of slaves that you desire etc This tutorial gives you an example on how to use create a correct configuration file provide the host machines for your servers and finally how to run the setup.py script In order to use the CPFMachines package you will have to create some custom configuration files that will define some basic properties of your server setup It is not necessary but recommended that you add these files to a git repository You can also use this repository to add other files with helper scripts and such that you use for handling your infrastructure We now add the CPFMachines package as a git submodule If you want your CPF project to be build on Linux and Window you have to at least provide one Debian 8.9 and one Windows 10 machine This tutorial assumes this minimalist setup The machines can be virtual or physical ones After you learned the basics you can still add more machines for in order to provide more build slaves If you do not care for Windows builds you can leave away the Windows machine If you only want to do Windows builds you will still need the Linux machine as it will host the jenkins and web server Get two fresh physical or virtual machines and install Windows 10 on one and Debian 8.9 on the other Both machines must be attached to the local network Create an account on the Debian machine that can be accessed via SSH Install docker on the debian machine Create an account on the Windows machine that can be accessed via SSH with the Bitvise SSH server Install build tools on the Windows machine Add more detailed instructions for the above steps Currently more manual steps are required The further steps assume that you can now run on the machine that you want to use to run the setup.py script Replace the user and machine names with the ones that you actually use We now add a configuration file to our MyCPFMachines repository The file contains information about our host machines and which build-jobs we want to have on the CI server Add a new file MyCPFMachines/MyConfig.json with the following content MyConfig.json With this configuration you will get the jenkins master server a jenkins linux agent and the web-server on the mydebianpc machine The mywindowspc will be used to run a jenkins windows agent Jenkins will be configured to have one build job MyCPFProject that will build your CPF project You can get more information about the configuration file here Adding passwords for your accounts to the config file is optional It may be saver to leave them out but it comes with the inconvenience that you have to re-enter them whenever you want to run the setup.py script Improve the setup script to allow the creation of an admin account on the first run We now have done all the manual preparations that are necessary to install the servers Running the script may take quite some time as some of the required tools are freshly compiled when running the script If the script fails to run successfully see if you can find the problem on the trouble shooting page here</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFSolvedProblems</field>
    <field name="url">dd/d72/_c_p_f_solved_problems.html</field>
    <field name="keywords"></field>
    <field name="text">Problems solved by the CPF This page is the sales brochure for the CPF It lists a number of problems that I encountered while working on professional C++ projects and that the CPF tries to solve or wants to solve in the future It should give you all the reasons you need for switching over to the CPF side of the force A list of problems that are solved by the current CPF version Problem Your are new to the fascinating world of C++ and maybe even programming You want to set up your long term cross-platform C++ codebase but you have enough trouble with getting your source code to compile You have no experience in defining a directory structure for your code splitting your code into libraries or providing binary packages for your users Solution The CPF does this and more for you If you set up a new code-base you should try the CPF Problem You would like to use the latest CMake features in your project but you are not to eager to spend the time become a CMake expert and update your CMake code Solution The CPF hides all the implementation details of a modern CMake project behind a relatively small interface I may not be a CMake expert but I have spend quite some time with it now and I try to keep the CPF s CMake code at the state of the art Feel free to inform me if you think that something in the CPF could be done better than it is done today Problem When using vanilla CMake the project configurations that you defined with CMakes options are lost when you delete your build-tree Solution The CPF config file mechanics keeps your configuration out of the build-tree Problem You are not the youngest anymore and you have trouble remembering long lists of CMake cache variable names that you need when configuring your project with CMake on the command line You also fall asleep while trying to enter the long commands in the console Solution The CPF config file mechanics keeps the command lines short and lets you edit your configuration in a text-file that already lists all available variables Problem You dont want to specify the source and build directories whenever you have to re-generate your make-files with CMake Solution A CPF project has defined locations for the source- and build-tree This allows it to remove the need for specifying them when calling its CMake wrapper scripts Is that all here Problem You want to define a set of officially supported project configurations These configurations should be build by the CI server to verify they work Solution The CPF config file mechanics allow adding a fixed set of build configurations to your project If you use the CI server of the CPFMachines package it will automatically build the defined configuration Problem You want a unique version to be injected into the build for each commit The version should come from your git repository and support official release versions as well as intermediate developer versions Solution The CPF does this for you Problem You realized that implementing your CI pipeline with linear scripts caused your build-times to explode when you added additional pipeline tasks Solution The CPF uses CMakes custom target mechanism to implement all build-steps This allows your build-tool to run tasks in parallel that do not depend on each other Problem While implementing your CI pipeline with linear scripts you realized that you would like to automatically re-execute your pipeline steps when source files change and to not re-execute them when they are up to date You really do not have the time to implement a frame-work for this Solution Again with the custom targets we exploit that this functionality has already been implemented by your build-system Problem You would like to regularly run clang-tidy on your code but you have no time to write the required scripts Solution The CPF provides a custom target per package to run clang-tidy Problem You would like to regularly run your automated tests with valgrind but you have no time to write the required scripts Solution The CPF provides a custom target that implements that add all custom targets Problem You need to setup a build-server and configure a build-job for your C++ project Solution The CPF provides a script that sets-up the server and the build-job for your CPF project Problem You need a web-server to host the html-pages that are generated by your CI pipeline Solution The CPF will setup that server for you and the build-job will make sure that the html pages are updated with each build Problem You installed a complex infrastructure of build-servers build-jobs and web-servers No you realize that you cannot remember how you did it or that you forgot to maintain your documentation properly Solution The CPF generates the server infrastructure completely from scripts using docker containers This means that you can check your machine configuration into a repository and always re-create it when it somehow gets lost The scripts also document how the machines are set up A list of problems that we would like to solve in the future Problem When working on a large codebase we would like to import packages that we do not change as binary packages in order to reduce build times Sometimes it turns out that we need to change those packages after all maybe in order to fix a bug Now we would prefer if the package was inlined in our projects source tree in order to get quick edit-build cycles The CPF wants to make this change possible by simply setting a flag in the configurations file For inlined packages we can use git submodules and for binary packages the hunter package manager Problem Your realized that putting your code-base into one monolithic repository forces you to globally adapt all packages to API-changes in a lower level package You now want a solution with multiple repositories that allows using multiple versions of a package at the same time and do step-wise dependency updates Solution The CPF believes it supports this but it has not been tested The plan is to make sure this works in the future</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index::CPFWorkingWithCPF</field>
    <field name="url">d4/d37/_c_p_f_working_with_c_p_f.html</field>
    <field name="keywords"></field>
    <field name="text">Working with a CPF project This page provides practical information on how to do the day to day tasks that arise when working with a CPF project The text refers to an example project that can be retrieved from Github to illustrate the required steps Before you start you have to install the basic tools that are used by the CMakeProjectFramework Find out what must be installed by hand to compile the project Windows Visual Studio 2017 Git Python3 CMake 3.12.1 OpenCppCoverage optional Doxygen Linux Gcc Git Python3 CMake 3.12.1 Clang optional Valgrind optional Doxygen Git Python and CMake should be callable from the command-line PATH on Windows A CPF project must be based on a git repository The CMake code relies on it when determining package versions and when handling packages that can be contained in git submodules Because of the contained submodules the repository must be cloned by using In order to build a freshly cloned CPF project four commands need to be exectuted Sadly this is a little more effort then the normal two steps generate and build that are used for a vanilla CMake project The steps are implemented with the following Python 3 scripts 0_CopyScripts.py Copies the other scripts to the projects root directory 1_Configure.py Adds a CMake configuration for the project 2_Generate.py Create the make-files for a project configuration 3_Make.py Build the project If you have your operating system configured to run py files with python 3 you can omit the explicit call to python in the following command line examples If this is not the case make sure the python version call returns a 3.X version On Linux you may need to use python3 instead of python In order to execute the copy step run in the project root directory This step copies some python scripts into the project s root directory The scripts are provided by the CPFBuildscripts package The scripts are only copied to shorten the command-line calls while working with the project This step only needs to be executed once after cloning the repository In order to generate a configuration file run on Windows or on Linux in the project root directory The purpose of the configuration step is to create the Configuration/ config config.cmake file that contains a set of CMake cache variables These variables determine things like the CMake generator or which custom targets are included in the pipeline The config file is used instead of the usual variable definitions in the CMake generate step The name of the configuration here VS or Gcc can be chosen freely The inherits option determines a base configuration from which the created file inherits default values for all required variables The base configuration can be provided by the CPFCMake package or the projects CIBuildConfigurations directory which is the common use case Some of the values in the configuration file like library locations or test file directories must be set to values that are specific to the machine onto which the project was cloned After running the script you have the chance to edit the default values in the created config file in order to change the values to something that is adequate for the local build On a CI server it may sometimes be useful to set non default values of variables directly with the command line call This can be done by adding options to the script call A project can have multiple configurations in parallel This can be achieved by running the 1_Configure.py script multiple times with different configuration names However if only one configuration is available the configuration argument can be omitted in the following generate and build steps The custom mechanism with the additional configuration file distinguishes the workflow of the CPF project from the standard CMake command line workflow where the configure and generate step are executed at the same time A disadvantage of CPF S config file mechanism is that configuration information is duplicated in the config.cmake file and the CMakeCache.txt file The developer has to remember that instead of editing the CMakeCache.txt file one now has to edit the config.cmake file and then re-execute the generate step The additional command line call may also come unexpected to developers who are used to work with normal CMake projects However CMake itself provides a similar three step work-flow when using the CMake-GUI application Here the user can also change values of variables in the CMakeCache.txt file before executing the generate step This indicates that there is a certain need for a three-step approach The CPF mechanism has some advantages over the two step work-flow which in my opinion outweigh the disadvantages Developers are relieved of remembering long lists of variable definitions that need to be typed whenever they need to re-generate the project Especially when working on CMake code it becomes often necessary to delete the build directory in order to create fresh project With the CPF mechanism the manual work of creating a project configuration is not lost when the build directory is deleted The project can define default configurations that are used by the projects CI job This can be used to define officially supported compiler configurations and platforms To execute the generate step run on Windows or on Linux in the project root directory The generate step is the equivalent to the normally used cmake call In fact running the command will print the underlying CMake command line The command creates the build-directory Generated/VS that holds the generated make-files for the generator that is set in the config file In this example this is the Visual Studio solution for the Windows case and the make files in the Linux case When called with the configuration argument the script will delete the build directory before generating the make-files to guarantee that its content is clean The script can be called without the configuration argument In this case it will use the first configuration that is available in the Configuration directory It will also not delete the build directory before generating the files and do a faster incremental generate instead The script sometimes fails to clear the build directory See CPFBuildscripts issue 1 To execute a full build run on Windows or on Linux This will compile the binaries as well as executing extra pipeline tasks like running the tests do analysis generate the documentation or other steps that your project may have enabled via its configuration file Specifying the the cpf-configuration will cause a fresh rebuild If no cpf-configuration is specified the script will do an incremental build for the first configuration in the Generated directory With the target option one can specify which target should be build During development this is useful if only a smaller part of the pipeline should be executed Here is a list of available custom targets If the target option is omitted completely the script will only build the binary targets of the project The config option is only required for multi-configuration generators like Visual Studio If it is not specified the Debug configuration will be build Now that you have built the project it is time to take a look at the content of the test project The CMakeProjectFramework enforces a certain directory structure Here are the most important parts of that directory layout Note that depending on the configuration that you built not all of the shown directories and files will exist in your project Many of the displayed directories do not exist in a freshly cloned CPF project The ACPFTestProject directory is the root directory of the project This is the directory that you get when cloning a CPF project Most of the command line operations that are needed to handle the CPF project are executed in this directory The directory contains scripts to configure and build the project It also contains the Sources Configuration and Generated directories The Sources directory is stored in the repository while the other two are generated when setting up the project The Sources directory contains all the files that are checked into the repository After cloning a CPF repository this should be the only existing directory in the cpf-root-directory The Sources directory contains the root CMakeLists.txt file of the repository global files and directories for the packages that contain the payload code of the project There is a set of files that are in every CPF project CMakeLists.txt The root CMakeLists.txt file creates the CI-project This is the host project that contains the package projects that are created by the packages CMakeLists.txt files The CPF dependencies are pulled in by including cpfInit cmake The Packages are added by calling the cpfAddPackages() function Both are provided by the CPFCMake package packages.cmake This file defines a CMake variable that holds a list of package names that are OWNED by this CI-project or are EXTERNAL packages Owned means that the CI-job that builds this repository is responsible for verifying that all automated checks for the package pass before it is marked with a version tag More information about package ownership can be found here CIBuildConfigurations This directory provides the CI job with information about the project configurations that should be build by the CI job These configurations are defined in files like VS.config.cmake which contain a set of CMake cache variables More information about the config file mechanism can be found here CIBuildConfigurations/cpfCiBuildConfigurations.json A file that contains a list of configurations that are build by the projects CI job This is only needed if the infrastructure provided by CPFMachines is used APackage A directory that contains a package The name of the package directory can be chosen by the user It also defines the name of the main library executable or custom target that is created by this package A CPF project can have multiple package directories The package directory contains all source files that belong to the package These can hold the production code test code or the package documentation The package directory must contain a CMakeLists.txt file that calls the cpfInitPackageProject() and one of the cpfAdd&lt;X&gt; Package functions The directory structure within the package directory can be chosen freely The relative directories of source files must be prepended when adding the files to the packages CMakeLists.txt file The Configuration directory contains CMake files that define the locally used configurations of the project This directory is generated by calling the 1_Configure.py script in the configuration step This directory is used to keep manually created project configurations out of the potentially short lived Generated directory The Generated directory contains all files that are generated by the generate- and build step All contents of that directory can be deleted without loosing any manual work However you will have to re-execute the generate and build step after deleting this directory The Generated directory contains one subdirectory for each configuration for which the generate step is executed The configuration directories are the CMake build directories that contain the usual CMake generated files as well as some special directories that are created by the CMake code of the CPF CPF specific build directory content Generated/ config The primary output directory of the project It contains created distribution packages in the Downloads subdirectory The doxygen subdirectory contains the entry page of the generated project page which leads to the documentation and other optionally generated html pages like coverage report Generated/ config This directory contains all the binaries that are generated when building the project When running an executable during debugging or automated testing it is run from within this directory Generated/ config A directory that is used for all internal files that are generated by the custom targets of the CPFCMake package If everything goes well the contents are only of interest when developing the CPFCMake package itself Generated/ config A directory that is used to accumulate the contents of the created distribution packages If everything goes well the contents are only of interest when developing the CPFCMake package itself The basic concepts page mentions that the CPF wants to separate CI-functionality from production code In the repository this is reflected by the two layers of CMakeLists.txt files The CI-project is defined by the root CMakeLists.txt file in the Sources directory The package projects are defined by the CMakeLists.txt files in the Sources package directories In the ACPFTestProject we have quite a number of packages The packages APackage CPackage DPackage documentation and EPackage are listed in the Sources/packages.cmake file which defines them as owned packages This means that it is this CI-project s responsibility to provide their official build-job that increments their version tags CPackage and documentation are fixed packages which means that they are in the same repository as the CI-project It is called fixed because this fixes the package version to the version of the CI-project The other owned packages are loose because they are pulled in via the git-submodule mechanism which allows them to have their version incremented independently from the other packages The packages BPackage CPFBuildscripts CPFCMake documentation FPackage GPackage and libSwitchWarningsOff are external packages External packages are always pulled in via the git-submodule mechanism Describe to most common git operations update of packages etc The cpfAddCppPackage function allows you to create binary packages for your library targets These packages contain cmake* files that can be used by other CMake based projects to consume your libraries with the find_package CONFIG function Currently binary packages with internal versions are not consumable by other cmake projects This is because the standard package files do not know how to handle the internal version number format of the CPF</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">todo</field>
    <field name="url">dd/da0/todo.html</field>
    <field name="keywords"></field>
    <field name="text">Todo List Page Automatic build-Job execution Add documentation for hook config and how to run it Page Basic Concepts Add a nice diagram of a monolithic project vs a distributed one Page CPF configurations Add documentation of the default configurations example configs etc Maybe put the section about the configuration mechanism from the working with a cpf project in here Page Current problems Add list Page Distribution packages Discuss package creation and package consumption Page How to setup the CPFMachines infrastructure Setup infrastructure on fresh systems and complete the list This section has overlapping content with Setting up the CPF CI server infrastructure We should merge them together Automatically add the content of the example config file here and manually add comments Change webserver file structure that multiple project pages can be served serachindex and an index.html in the base directory provides links to the single projects Page Machines and Container Buy a more powerfull build-machine to reduce the overall pipeline time Page Problems solved by the CPF Is that all here add all custom targets Page Setting up the CPF CI server infrastructure Add more detailed instructions for the above steps Improve the setup script to allow the creation of an admin account on the first run Page Test targets Explain about test targets and the command line interface What options will the cpf give to the test exe in order to run fast tests and hand over test file directories Should it be possible for users to hand over their own options Page The CPFMachines config file This page should provide information about all the parameter in the config file and what they do Page Working with a CPF project Find out what must be installed by hand to compile the project Describe to most common git operations update of packages etc</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">bug</field>
    <field name="url">de/da5/bug.html</field>
    <field name="keywords"></field>
    <field name="text">Bug List Page Machines and Container Network issues after running setupDockerContainer.sh Setting up the docker container changes the network settings of the host This may cause the the setupDockerContainer.sh script to fail when run multiple times in a row because connection to the internet can not be made Restarting the machine on which the script is run will solve the problem Page Working with a CPF project The script sometimes fails to clear the build directory See CPFBuildscripts issue 1</field>
  </doc>
  <doc>
    <field name="type">page</field>
    <field name="name">index</field>
    <field name="url">index.html</field>
    <field name="keywords"></field>
    <field name="text">Overview The CMakeProjectFramework The CMakeProjectFramework framework provides a solution for organizing a cross-platform Git and CMake based C++ software project At the low level it implements the execution of additional tasks like test-execution packaging or documentation generation This part is implemented with CMake and can be used without the higher level part which implements a Jenkins based CI-infrastructure that can be used to provide continuous integration services for a CPF project This project is work in progress The release 1.0 has yet to come Index Introduction to the CPF Introduction A short overview over what the CPF does Problems solved by the CPF Read this if you want to know why you should use the CPF Basic Concepts Some fundamental design concepts of the project Tutorials Working with a CPF project A tutorial on how to work with an existing CPF project Setting up a CPF project A tutorial on how to create your own CPF project Setting up the CPF CI server infrastructure A tutorial on how to set up the build- and web-server for a CPF project Developer references Project Organization An overview of the packages that make up the CMakeProjectFramework CPFCMake More detailed information about the CPFCMake package CPFBuildscripts More detailed information about the CPFBuildscripts package CPFMachines More detailed information about the CPFMachines package CPFTests High-level tests for the complete CMakeProjectFramework Motivation In the smaller sized teams and companies that I have worked with improving the CI system was often a somewhat neglected part of the development Although the eco-system provides a number of open source tools that do the heavy lifting it is still quite some work to integrate all the tools into a full featured CI production system Implementing new features in the production code often had higher priority then the work on the infrastructure This situation bugged me and I started to implement a CI pipeline and infrastructure for my own C++ toy code-base At some point the infrastructure code started to get bigger then the C++ payload code I decided to pull the infrastructure code out into its own repository which now has become the CMakeProjectFramework At it s current state the project is not battle tested As far as I know I am the only user and the project currently lacks the generality to be useful to everybody However I am interested in changing that and making the project useful to hobby developers or small teams that have not yet a CI pipeline in place If you are interested in using the project or joining its development feel free to contact me via Github Limitations The CMakeProjectFramework is currently only developed on Linux and Windows In the long run I would also like to support development on MacOS and cross-compiling to any other platform that is supported by CMake Setting up the CI infrastructure currently requires still a lot of manual work When using the CPF on Windows one can easily run into the 260 character limit for filesystem paths If this is hit the only fix is to reduce the length of package names and the project name On Windows 10 the limit can be switched off though Similar projects Here is a probably incomplete list of projects that have functionality overlaps with the CPF build2 Meson BASIS JAWS</field>
  </doc>
</add>
